#!/usr/bin/env python3
"""
HSRI Weather Dashboard - Streamlit App
Interactive map showing HSRI, temperature, and clothing recommendations across NYC metro.
Uses metro.csv for county-level geographic information.
Deploy to Streamlit Cloud with: streamlit cloud deploy
"""

import streamlit as st
import pandas as pd
import numpy as np
import folium
from streamlit_folium import st_folium
from datetime import datetime, timedelta
import plotly.graph_objects as go
from sklearn.linear_model import LinearRegression
import warnings
import os
#warnings.filterwarnings('ignore')

# Define the base directory of your script file
DIR_NAME = os.path.dirname(os.path.abspath(__file__))

# ============================================================================
# PAGE CONFIG
# ============================================================================
st.set_page_config(
    page_title="NYC HSRI Weather Dashboard",
    page_icon="üå§Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("üå§Ô∏è NYC Metro HSRI Weather Dashboard")
st.markdown("**Heat Stress Risk Index** ‚Ä¢ Real-time conditions & clothing recommendations")

# ============================================================================
# LOAD DATA
# ============================================================================
@st.cache_data
def load_weather_data():
    """Load and preprocess weather CSV, filtering for core meteorological data."""
    # Use os.path.join for cross-platform path creation
    filepath = os.path.join(DIR_NAME, 'data', 'weather.csv')
    
    df = pd.read_csv(filepath)
    df['datetime'] = pd.to_datetime(df['datetime'])
    
    # Filter for rows with core meteorological parameters only
    required_cols = ['temp', 'humidity', 'windspeed']
    df = df.dropna(subset=required_cols)
    
    # Keep solar radiation, UV index, and cloud cover as-is (with NaN for missing values)
    # These will be handled as "N/A" in display
    
    return df

@st.cache_data
def load_metro_data():
    """Load metro area county data."""
    try:
        # Use os.path.join for cross-platform path creation
        filepath = os.path.join(DIR_NAME, 'data', 'metro.csv')
        metro_df = pd.read_csv(filepath)
        return metro_df
    except FileNotFoundError:
        return None

def load_site_data(weather_df=None):
    """Load site metadata - dynamically from weather data or defaults."""
    if weather_df is None:
        weather_df = load_weather_data()
    
    # Get unique AQS IDs from weather data
    unique_aqs_ids = weather_df['aqs_id_full'].unique()
    
    # Create mapping for known/major NYC metro AQS IDs
    aqs_mapping = {
        # NYC (5 Boroughs)
        840421010055: ('Manhattan-Midtown', 'New York County', 40.7614, -73.9776),
        840421010075: ('Manhattan-Upper West', 'New York County', 40.7831, -73.9712),
        840421010048: ('Manhattan-Upper East', 'New York County', 40.7688, -73.9519),
        840090010010: ('Brooklyn-Downtown', 'Kings County', 40.6501, -73.9496),
        
        # Queens
        840360470052: ('Queens-Astoria', 'Queens County', 40.7673, -73.9302),
        840360470118: ('Queens-Jamaica', 'Queens County', 40.7014, -73.8156),
        
        # Bronx
        840360610135: ('Bronx-SW', 'Bronx County', 40.8298, -73.8850),
        840360610115: ('Bronx-Pelham', 'Bronx County', 40.8648, -73.8276),
        
        # Staten Island
        840360850055: ('Staten Island-Fresh Kills', 'Richmond County', 40.5834, -74.1677),
        840360850111: ('Staten Island-Coney Island', 'Richmond County', 40.5755, -74.1333),
        
        # Westchester County
        840360050080: ('Westchester-Yonkers', 'Westchester County', 40.9230, -73.8987),
        840360050110: ('Westchester-Mamaroneck', 'Westchester County', 40.9450, -73.7350),
        840360050112: ('Westchester-Croton', 'Westchester County', 41.1833, -73.8667),
        
        # New Jersey - Bergen & Hudson
        840360710002: ('NJ-Hudson', 'Hudson County', 40.7178, -74.0569),
        
        # Connecticut
        840090090027: ('CT-New Haven', 'New Haven County', 41.3083, -72.9279),
        840090110124: ('CT-Bridgeport', 'Fairfield County', 41.1833, -73.1833),
        840090011123: ('CT-Stamford', 'Fairfield County', 41.0534, -73.5387),
        
        # Long Island - Nassau & Suffolk
        840340030010: ('Nassau-NW', 'Nassau County', 40.8333, -73.6667),
        840340070010: ('Nassau-Central', 'Nassau County', 40.8500, -73.5000),
        840340170008: ('Suffolk-E', 'Suffolk County', 40.9500, -72.8000),
        840340171003: ('Suffolk-SE', 'Suffolk County', 40.8667, -72.7333),
        840340210005: ('Suffolk-Central', 'Suffolk County', 40.9000, -72.9000),
        840340210008: ('Suffolk-NE', 'Suffolk County', 41.0500, -72.7500),
        840340390004: ('Nassau-SW', 'Nassau County', 40.6833, -73.5000),
        840340392003: ('Nassau-S', 'Nassau County', 40.6500, -73.6667),
        840340190001: ('Hempstead', 'Nassau County', 40.7550, -73.6219),
        840340273001: ('Freeport', 'Nassau County', 40.6575, -73.5819),
        840340230011: ('Rockville Centre', 'Nassau County', 40.6667, -73.6500),
        840340410007: ('Valley Stream', 'Nassau County', 40.6650, -73.7100),
        
        # Rockland County, NY
        840360810120: ('Rockland-W', 'Rockland County', 41.0880, -74.2435),
        840360810124: ('Rockland-S', 'Rockland County', 41.1333, -74.0333),
        
        # Orange County, NY
        840360870005: ('Orange County', 'Orange County', 41.3333, -74.2667),
        
        # Dutchess & Putnam Counties, NY
        840361030009: ('Dutchess County', 'Dutchess County', 41.6333, -73.7000),
        840361192004: ('Putnam County', 'Putnam County', 41.4667, -73.8667),
    }
    
    sites_list = []
    for aqs_id in unique_aqs_ids:
        if aqs_id in aqs_mapping:
            site_name, county, lat, lon = aqs_mapping[aqs_id]
            sites_list.append({
                'aqs_id_full': aqs_id,
                'site_name': site_name,
                'county': county,
                'latitude': lat,
                'longitude': lon
            })
        else:
            # For unknown AQS IDs, create generic entry with NYC center coordinates
            sites_list.append({
                'aqs_id_full': aqs_id,
                'site_name': f'Location-{aqs_id}',
                'county': 'Other',
                'latitude': 40.7128,  # NYC center
                'longitude': -74.0060
            })
    
    sites = pd.DataFrame(sites_list)
    return sites

# ============================================================================
# HSRI CALCULATION (from project specification)
# ============================================================================
def compute_hsri(temp_f, humidity, wind_speed, solar_radiation, uv_index, cloud_cover):
    """
    Compute Heat Stress Risk Index (HSRI).
    
    Formula: HSRI = HI_base + Œ±¬∑UV + Œ≤¬∑SR_eff ‚àí Œ≥¬∑WS [‚àí Œ¥¬∑CC]
    
    where:
    - HI_base: NWS Heat Index computed from temperature and humidity
    - UV: UV index (0-10+), higher increases radiant heat load
    - SR_eff: Effective solar radiation (W/m¬≤), scaled to ~0-1
    - WS: Wind speed (mph), cooling effect reduces HSRI
    - CC: Cloud cover (%), shading effect
    
    Calibrated weights: Œ±=0.3, Œ≤=8, Œ≥=4, Œ¥=0.05
    Missing values for solar, UV, and cloud cover are treated as 0
    """
    # NWS Heat Index (Rothfusz regression)
    hi_base = compute_hi_nws(temp_f, humidity)
    
    # Handle missing values for solar radiation, UV, and cloud cover
    sr_eff = 0 if pd.isna(solar_radiation) else max(0, solar_radiation / 1000.0)
    uv_val = 0 if pd.isna(uv_index) else uv_index
    cc_val = 0 if pd.isna(cloud_cover) else cloud_cover
    
    # HSRI components with empirically calibrated weights
    alpha, beta, gamma, delta = 0.3, 8.0, 4.0, 0.05
    hsri = hi_base + alpha * uv_val + beta * sr_eff - gamma * wind_speed - delta * cc_val
    
    return np.clip(hsri, -100, 100)  # Reasonable bounds for human comfort index

def compute_hi_nws(temp_f, humidity):
    """NWS Heat Index (Rothfusz regression)."""
    T = temp_f
    RH = humidity
    
    if T < 80:
        return T
    
    # Coefficients
    c1, c2, c3 = -42.379, 2.04901523, 10.14333127
    c4, c5, c6 = -0.22475541, -0.00683783, -0.05481717
    c7, c8, c9 = 0.00122874, 0.00085282, -0.00000199
    
    HI = (c1 + c2*T + c3*RH + c4*T*RH + c5*T**2 + c6*RH**2 +
          c7*T**2*RH + c8*T*RH**2 + c9*T**2*RH**2)
    return HI

def forecast_hsri(historical_data, days_ahead=3):
    """
    Forecast HSRI for next 1-3 days using Linear Regression.
    
    Based on project findings: Linear Regression (R¬≤ = 0.965) recommended
    for operational deployment due to interpretability and accuracy.
    """
    if len(historical_data) < 10:
        return None
    
    try:
        # Prepare features for modeling
        feature_cols = ['temp', 'humidity', 'windspeed', 'solarradiation', 'uvindex', 'cloudcover']
        X = historical_data[feature_cols].copy()
        
        # Fill NaN values in solar, UV, and cloud cover with column mean
        X['solarradiation'] = X['solarradiation'].fillna(X['solarradiation'].mean())
        X['uvindex'] = X['uvindex'].fillna(X['uvindex'].mean())
        X['cloudcover'] = X['cloudcover'].fillna(X['cloudcover'].mean())
        
        X = X.values
        y = historical_data['hsri'].values
        
        # Train linear regression
        model = LinearRegression()
        model.fit(X, y)
        
        # Generate forecast by interpolating future weather patterns
        avg_features = X.mean(axis=0)
        forecast_values = []
        
        for day in range(1, days_ahead + 1):
            # Simple trend: assume weather gradually changes
            forecast_features = avg_features * (1 + 0.02 * day)
            forecast_hsri = model.predict([forecast_features])[0]
            forecast_values.append(np.clip(forecast_hsri, -100, 100))
        
        return forecast_values
    except:
        return None

def get_risk_category(hsri):
    """Categorize heat risk based on HSRI threshold."""
    if hsri >= 85:
        return "üî¥ CRITICAL", "Critical Heat"
    elif hsri >= 75:
        return "üü† HIGH", "High Heat"
    elif hsri >= 65:
        return "üü° MODERATE", "Moderate Heat"
    elif hsri >= 50:
        return "üü¢ LOW", "Mild"
    elif hsri >= 30:
        return "üîµ COOL", "Cool"
    else:
        return "üü£ FREEZING", "Freezing"

# ============================================================================
# MAIN APP
# ============================================================================

# Load data
try:
    weather_df = load_weather_data()
except FileNotFoundError:
    st.error("‚ùå `weather.csv` not found in data/ folder.")
    st.stop()

sites_df = load_site_data(weather_df)
metro_df = load_metro_data()

# Custom CSS for better styling
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
    }
    .risk-critical { color: #d62728; font-weight: bold; }
    .risk-high { color: #ff7f0e; font-weight: bold; }
    .risk-moderate { color: #ffbb78; font-weight: bold; }
    .risk-low { color: #2ca02c; font-weight: bold; }
</style>
""", unsafe_allow_html=True)

# ====================================================================
# SIDEBAR CONTROLS
# ====================================================================
st.sidebar.header("‚öôÔ∏è Dashboard Controls")

# Time selection - use date and time inputs instead of slider
col_date, col_time = st.sidebar.columns(2)

min_date = weather_df['datetime'].min().date()
max_date = weather_df['datetime'].max().date()

with col_date:
    selected_date = st.date_input(
        "üìÖ Date",
        value=min_date,
        min_value=min_date,
        max_value=max_date
    )

with col_time:
    selected_hour = st.selectbox(
        "üïê Hour (UTC)",
        options=range(0, 24),
        index=0,
        help="Select hour (0-23)"
    )

# Construct datetime
selected_datetime = datetime.combine(selected_date, datetime.min.time()).replace(hour=selected_hour)

# HSRI Risk Threshold - use number input instead of slider
hsri_threshold = st.sidebar.number_input(
    "üå°Ô∏è HSRI Risk Threshold",
    min_value=-100,
    max_value=100,
    value=65,
    step=5,
    help="Show locations with HSRI >= threshold"
)

# NYC Borough/Area selection - ONLY show areas that have data
st.sidebar.markdown("### üìç NYC Area Selection")

# Get sites available for current time
available_times = weather_df['datetime'].unique()
if pd.Timestamp(selected_datetime).tz is None:
    selected_ts = pd.Timestamp(selected_datetime, tz='UTC')
else:
    selected_ts = pd.Timestamp(selected_datetime)

closest_time = min(available_times, key=lambda x: abs((x - selected_ts).total_seconds()))
df_time = weather_df[weather_df['datetime'] == closest_time].copy()
df_time = df_time.merge(sites_df, on='aqs_id_full', how='left')

# Get only known sites (not Location-XXXXX) that have data at this time
known_sites_available = df_time[~df_time['site_name'].str.contains('Location-', regex=False)]['site_name'].unique().tolist()

if not known_sites_available:
    # Fallback to all available sites
    known_sites_available = df_time['site_name'].unique().tolist()

# Create borough options ONLY with sites that exist in current data
nyc_areas = {'All Areas': known_sites_available}

predefined_areas = {
    'Manhattan': ['Manhattan-Midtown', 'Manhattan-Upper West', 'Manhattan-Upper East'],
    'Brooklyn': ['Brooklyn-Downtown'],
    'Queens': ['Queens-Astoria', 'Queens-Jamaica'],
    'Bronx': ['Bronx-SW', 'Bronx-Pelham'],
    'Staten Island': ['Staten Island-Fresh Kills', 'Staten Island-Coney Island'],
    'Westchester': ['Westchester-Yonkers', 'Westchester-Mamaroneck', 'Westchester-Croton'],
    'Long Island (Nassau)': ['Nassau-NW', 'Nassau-Central', 'Nassau-SW', 'Nassau-S', 'Hempstead', 'Freeport', 'Rockville Centre', 'Valley Stream'],
    'Long Island (Suffolk)': ['Suffolk-E', 'Suffolk-SE', 'Suffolk-Central', 'Suffolk-NE'],
    'New Jersey': ['NJ-Hudson'],
    'Connecticut': ['CT-New Haven', 'CT-Bridgeport', 'CT-Stamford'],
    'Rockland County': ['Rockland-W', 'Rockland-S'],
    'Orange/Dutchess': ['Orange County', 'Dutchess County', 'Putnam County']
}

for area_name, sites in predefined_areas.items():
    available_for_area = [s for s in sites if s in known_sites_available]
    if available_for_area:
        nyc_areas[area_name] = available_for_area

selected_area = st.sidebar.selectbox(
    "Select NYC Borough/Area",
    list(nyc_areas.keys()),
    help="Only shows areas with available data"
)

st.sidebar.divider()
st.sidebar.markdown("### üìä Project Info")
st.sidebar.info("""
**Short-Term Heat Stress Forecasting**

Reduces heat-related hospital admissions by 20% through neighborhood-level predictions.

**Model:** Linear Regression (R¬≤ = 0.965)
**Update Frequency:** Hourly
**Coverage:** All Available Stations
""")

st.sidebar.info(f"üìç Data for: **{pd.Timestamp(closest_time).strftime('%Y-%m-%d %H:%M UTC')}**")

# ====================================================================
# CREATE TABS
# ====================================================================
tab_dashboard, tab_forecast_map, tab_weather, tab_financial, tab_about = st.tabs(["üìä Dashboard", "üîÆ Forecast Map", "üå¶Ô∏è Weather Details", "üí∞ Financial Impact", "‚ÑπÔ∏è About"])

# ====================================================================
# TAB 1: DASHBOARD
# ====================================================================
with tab_dashboard:
    
    df_current = df_time.copy()
    
    if not df_current.empty and len(df_current) > 0:
        # Compute HSRI for current snapshot
        df_current['hsri'] = df_current.apply(
            lambda row: compute_hsri(
                row.get('temp', 70),
                row.get('humidity', 50),
                row.get('windspeed', 5),
                row.get('solarradiation', 500),
                row.get('uvindex', 5),
                row.get('cloudcover', 50)
            ), axis=1
        )
        
        # Enrich with metro data if available
        if metro_df is not None:
            df_current = df_current.merge(
                metro_df, 
                left_on='county', 
                right_on='county', 
                how='left'
            )
        
        # Add risk categories
        if not df_current.empty and len(df_current) > 0:
            risk_data = df_current['hsri'].apply(lambda x: pd.Series(get_risk_category(x)))
            if risk_data.shape[1] >= 2:
                df_current['risk_emoji'] = risk_data.iloc[:, 0]
                df_current['risk_text'] = risk_data.iloc[:, 1]
            else:
                df_current['risk_emoji'] = 'N/A'
                df_current['risk_text'] = 'N/A'
        else:
            df_current['risk_emoji'] = 'N/A'
            df_current['risk_text'] = 'N/A'
        
        # Filter by selected area/borough
        selected_sites = nyc_areas[selected_area]
        df_area = df_current[df_current['site_name'].isin(selected_sites)].copy()
        
        if df_area.empty:
            df_area = df_current.copy()
        
        # Filter by HSRI threshold
        df_high_risk = df_area[df_area['hsri'] >= hsri_threshold].copy()
        
        # ====================================================================
        # ROW 1: KEY METRICS
        # ====================================================================
        st.header(f"Real-time Heat Stress Monitoring - {selected_area}")
        
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            avg_hsri = df_area['hsri'].mean() if not df_area.empty else None
            if pd.notna(avg_hsri):
                st.metric("üìä Avg HSRI", f"{avg_hsri:.1f}¬∞F")
            else:
                st.metric("üìä Avg HSRI", "N/A")
        
        with col2:
            max_hsri = df_area['hsri'].max() if not df_area.empty else None
            if pd.notna(max_hsri):
                risk_emoji, risk_text = get_risk_category(max_hsri)
                st.metric("üî• Peak HSRI", f"{max_hsri:.1f}¬∞F", delta=risk_text)
            else:
                st.metric("üî• Peak HSRI", "N/A")
        
        with col3:
            high_risk_count = len(df_high_risk) if not df_high_risk.empty else 0
            st.metric("‚ö†Ô∏è High-Risk Sites", high_risk_count)
        
        with col4:
            avg_temp = df_area['temp'].mean() if 'temp' in df_area.columns and not df_area.empty else None
            if pd.notna(avg_temp):
                st.metric("üå°Ô∏è Avg Temp", f"{avg_temp:.1f}¬∞F")
            else:
                st.metric("üå°Ô∏è Avg Temp", "N/A")
        
        with col5:
            avg_humidity = df_area['humidity'].mean() if 'humidity' in df_area.columns and not df_area.empty else None
            if pd.notna(avg_humidity):
                st.metric("üíß Avg Humidity", f"{avg_humidity:.0f}%")
            else:
                st.metric("üíß Avg Humidity", "N/A")
        
        st.divider()
        
        # ====================================================================
        # HSRI DISTRIBUTION & FORECAST
        # ====================================================================
        col_dist, col_forecast = st.columns(2)
        
        with col_dist:
            st.subheader("üìà HSRI Distribution")
            
            fig = go.Figure()
            fig.add_trace(go.Histogram(
                x=df_current['hsri'],
                nbinsx=15,
                marker_color='#FF6B6B',
                name='HSRI',
                hovertemplate='HSRI Range: %{x}<br>Count: %{y}<extra></extra>'
            ))
            fig.add_vline(
                x=hsri_threshold, 
                line_dash="dash", 
                line_color="darkred", 
                line_width=2,
                annotation_text=f"Threshold: {hsri_threshold}",
                annotation_position="top right"
            )
            fig.update_layout(
                title="Distribution Across All Sites",
                xaxis_title="HSRI Value",
                yaxis_title="Number of Sites",
                height=400,
                template="plotly_white",
                showlegend=False
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col_forecast:
            st.subheader("üîÆ 3-Day HSRI Forecast")
            
            forecast = forecast_hsri(df_current, days_ahead=3)
            
            if forecast:
                forecast_dates = [closest_time + timedelta(days=i) for i in range(1, 4)]
                forecast_data = pd.DataFrame({
                    'Date': forecast_dates,
                    'Forecast HSRI': forecast
                })
                
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=forecast_data['Date'],
                    y=forecast_data['Forecast HSRI'],
                    mode='lines+markers',
                    name='Forecast',
                    line=dict(color='#FF6B6B', width=3),
                    marker=dict(size=10)
                ))
                fig.add_hline(
                    y=hsri_threshold,
                    line_dash="dash",
                    line_color="darkred",
                    annotation_text=f"Threshold: {hsri_threshold}"
                )
                fig.update_layout(
                    title="Next 3 Days",
                    xaxis_title="Date",
                    yaxis_title="Predicted HSRI",
                    height=400,
                    template="plotly_white",
                    hovermode='x unified'
                )
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("‚ö†Ô∏è Insufficient data for forecasting")
        
        st.divider()
        
        # ====================================================================
        # OPERATIONAL INSIGHTS
        # ====================================================================
        st.subheader("üí° Operational Insights")
        
        insight_col1, insight_col2, insight_col3 = st.columns(3)
        
        with insight_col1:
            pct_high_risk = (len(df_high_risk) / len(df_current) * 100) if len(df_current) > 0 else 0
            st.metric("üè¢ Cooling Centers to Activate", f"{len(df_high_risk)} of {len(df_current)}", 
                     delta=f"{pct_high_risk:.1f}%")
            st.caption("Estimated cost savings: 40% reduction from reactive approach")
        
        with insight_col2:
            if not df_high_risk.empty and 'county' in df_high_risk.columns:
                top_county = df_high_risk['county'].value_counts().idxmax()
                st.metric("üìç Most Affected County", top_county)
                st.caption(f"{len(df_high_risk[df_high_risk['county']==top_county])} sites at high risk")
            else:
                st.metric("üìç Most Affected County", "N/A")
        
        with insight_col3:
            if max_hsri >= 75:
                st.metric("üè• Healthcare Alert", "HIGH ‚ö†Ô∏è")
                st.caption("Expect potential increase in heat-related ED visits")
            else:
                st.metric("üè• Healthcare Alert", "LOW ‚úÖ")
                st.caption("Normal operations expected")
        
        st.divider()
        
        # ====================================================================
        # MAP ON DASHBOARD
        # ====================================================================
        st.subheader("üó∫Ô∏è Geographic Heat Risk Map")
        
        # Create Folium map
        if not df_area.empty:
            center_lat = df_area['latitude'].mean()
            center_lon = df_area['longitude'].mean()
        else:
            center_lat = 40.7128
            center_lon = -74.0060
        
        if pd.isna(center_lat) or pd.isna(center_lon):
            center_lat = 40.7128
            center_lon = -74.0060
        
        m = folium.Map(
            location=[center_lat, center_lon],
            zoom_start=11,
            tiles='OpenStreetMap'
        )
        
        def get_marker_color(hsri_val):
            if hsri_val >= 85:
                return '#d62728'  # Critical - dark red
            elif hsri_val >= 75:
                return '#ff7f0e'  # High - orange
            elif hsri_val >= 65:
                return '#ffbb78'  # Moderate - light orange
            elif hsri_val >= 50:
                return '#2ca02c'  # Low - green
            elif hsri_val >= 30:
                return '#1f77b4'  # Cool - blue
            else:
                return '#6a0dad'  # Freezing - dark purple
        
        for _, row in df_area.iterrows():
            hsri_val = row.get('hsri', 0)
            site_name = row.get('site_name', 'Unknown')
            temp_val = row.get('temp', 'N/A')
            humidity_val = row.get('humidity', 'N/A')
            wind_val = row.get('windspeed', 'N/A')
            county = row.get('county', 'Unknown')
            
            risk_emoji, risk_text = get_risk_category(hsri_val)
            
            popup_text = f"""
            <div style="font-family: Arial; width: 300px;">
                <b style="font-size: 14px;">{site_name}</b><br/>
                <hr style="margin: 5px 0;">
                <b>County:</b> {county}<br/>
                <b>üå°Ô∏è Temperature:</b> {temp_val:.1f}¬∞F<br/>
                <b>üíß Humidity:</b> {humidity_val:.0f}%<br/>
                <b>üí® Wind Speed:</b> {wind_val:.1f} mph<br/>
                <hr style="margin: 5px 0;">
                <b style="font-size: 13px;">HSRI: {hsri_val:.1f}</b><br/>
                <b>{risk_emoji} {risk_text}</b>
            </div>
            """
            
            folium.CircleMarker(
                location=[row['latitude'], row['longitude']],
                radius=16,
                popup=folium.Popup(popup_text, max_width="300px"),
                tooltip=f"{site_name}: HSRI {hsri_val:.1f}",
                color=get_marker_color(hsri_val),
                fill=True,
                fillColor=get_marker_color(hsri_val),
                fillOpacity=0.7,
                weight=2
            ).add_to(m)
            
            # Add text label with HSRI value inside circle
            # Use darker text for light backgrounds (Moderate/Low levels)
            text_color = '#333333' if 50 <= hsri_val < 75 else 'white'
            text_shadow = '1px 1px 2px rgba(255,255,255,0.8)' if 50 <= hsri_val < 75 else '1px 1px 2px rgba(0,0,0,0.8)'
            
            folium.Marker(
                location=[row['latitude'], row['longitude']],
                icon=folium.DivIcon(html=f"""
                    <div style="
                        font-size: 13px;
                        font-weight: bold;
                        color: {text_color};
                        text-align: center;
                        text-shadow: {text_shadow};
                        width: 32px;
                        height: 32px;
                        display: flex;
                        align-items: center;
                        justify-content: center;
                        margin-left: -16px;
                        margin-top: -16px;
                    ">{hsri_val:.0f}</div>
                """)
            ).add_to(m)
        
        st_folium(m, width=1400, height=700)
        
        # Legend with Clothing Recommendations
        st.markdown("**üëï Risk Level Legend with Protective Clothing Guide**")
        
        recommendations = [
            ("85+", "ü©≥", "Shorts + Tank", "üî¥ Critical", "#ffe6e6", "#d62728"),
            ("75-84", "üëï", "Shorts + T-Shirt", "üü† High", "#fff0e6", "#ff7f0e"),
            ("65-74", "üëî", "Short Sleeves", "üü° Moderate", "#fffef0", "#ffbb78"),
            ("50-64", "üëó", "Light Layers", "üü¢ Low", "#f0fff0", "#2ca02c"),
            ("30-49", "üß•", "Light Jacket", "üîµ Cool", "#f0f8ff", "#1f77b4"),
            ("<30", "üß§", "Winter Coat", "üü£ Freezing", "#f3e6ff", "#6a0dad"),
        ]
        
        cols = st.columns(len(recommendations))
        for i, (hsri_range, clothing_emoji, clothing_desc, risk_label, bg_color, border_color) in enumerate(recommendations):
            with cols[i]:
                st.markdown(f"""
                <div style="padding: 12px; background-color: {bg_color}; border-left: 5px solid {border_color}; border-radius: 5px;">
                    <b>{risk_label}</b><br/>
                    <b>HSRI {hsri_range}</b><br/>
                    <div style="font-size: 28px; margin: 8px 0;">{clothing_emoji}</div>
                    <small>{clothing_desc}</small>
                </div>
                """, unsafe_allow_html=True)
    
    else:
        st.warning(f"‚ö†Ô∏è No data available for {selected_datetime.strftime('%Y-%m-%d %H:%M UTC')}. Please select a different time.")

# ====================================================================
# TAB 2: WEATHER DETAILS
# ====================================================================
with tab_weather:
    
    if not df_current.empty and len(df_current) > 0:
        st.subheader("üå¶Ô∏è Complete Weather Conditions by Site")
        st.markdown("Detailed weather variables and HSRI output for each location")
        
        for _, row in df_area.iterrows():
            site_name = row.get('site_name', 'Unknown')
            hsri_val = row.get('hsri', 0)
            risk_emoji, risk_text = get_risk_category(hsri_val)
            
            with st.expander(f"{risk_emoji} {site_name} - HSRI: {hsri_val:.1f}¬∞F"):
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.markdown("**Temperature & Humidity**")
                    st.metric("üå°Ô∏è Temperature", f"{row.get('temp', 'N/A'):.1f}¬∞F")
                    st.metric("üíß Humidity", f"{row.get('humidity', 'N/A'):.0f}%")
                
                with col2:
                    st.markdown("**Wind & Clouds**")
                    st.metric("üí® Wind Speed", f"{row.get('windspeed', 'N/A'):.1f} mph")
                    cc_val = row.get('cloudcover', 'N/A')
                    cc_display = "N/A" if pd.isna(cc_val) else f"{cc_val:.0f}%"
                    st.metric("‚òÅÔ∏è Cloud Cover", cc_display)
                
                with col3:
                    st.markdown("**Solar & UV**")
                    sr_val = row.get('solarradiation', 'N/A')
                    sr_display = "N/A" if pd.isna(sr_val) else f"{sr_val:.0f} W/m¬≤"
                    st.metric("‚òÄÔ∏è Solar Radiation", sr_display)
                    
                    uv_val = row.get('uvindex', 'N/A')
                    uv_display = "N/A" if pd.isna(uv_val) else f"{uv_val:.1f}"
                    st.metric("üå´Ô∏è UV Index", uv_display)
                
                with col4:
                    st.markdown("**Heat Stress Index**")
                    st.metric("üìä HSRI Output", f"{hsri_val:.1f}¬∞F")
                    st.metric("üìç County", row.get('county', 'N/A'))
                    st.caption(f"Updated: {closest_time.strftime('%H:%M UTC')}")
        
        # Data table
        st.subheader("üìã High-Risk Location Details")
        
        if not df_high_risk.empty:
            display_cols = ['site_name', 'county', 'temp', 'humidity', 'windspeed', 
                           'solarradiation', 'uvindex', 'cloudcover', 'hsri', 'risk_text']
            df_table = df_high_risk[[col for col in display_cols if col in df_high_risk.columns]].copy()
            
            df_table = df_table.rename(columns={
                'site_name': 'Site',
                'county': 'County',
                'temp': 'Temp (¬∞F)',
                'humidity': 'Humidity (%)',
                'windspeed': 'Wind (mph)',
                'solarradiation': 'Solar (W/m¬≤)',
                'uvindex': 'UV Index',
                'cloudcover': 'Cloud (%)',
                'hsri': 'HSRI',
                'risk_text': 'Risk Level'
            })
            
            st.dataframe(df_table, use_container_width=True, hide_index=True)
        else:
            st.info(f"‚úÖ No sites exceed HSRI threshold of {hsri_threshold}")

# ====================================================================
# TAB 3: FORECAST MAP
# ====================================================================
with tab_forecast_map:
    st.subheader("üîÆ 3-Day Historical HSRI Lookup & Forecast")
    st.markdown("View actual historical HSRI values or predict future heat stress risk across all monitoring locations")
    
    # Day selector for forecast
    forecast_day = st.selectbox(
        "Select day to view:",
        options=[1, 2, 3],
        format_func=lambda x: f"Day {x} ({(pd.Timestamp(closest_time) + timedelta(days=x)).strftime('%Y-%m-%d')})"
    )
    
    target_date = pd.Timestamp(closest_time) + timedelta(days=forecast_day)
    
    # Check if data exists for this date (convert to date for comparison)
    weather_df_dates = weather_df.copy()
    weather_df_dates['date'] = pd.to_datetime(weather_df_dates['datetime']).dt.date
    target_date_only = target_date.date()
    data_for_date = weather_df_dates[weather_df_dates['date'] == target_date_only]
    
    if not data_for_date.empty:
        st.info(f"‚úÖ Historical data available for {target_date.strftime('%Y-%m-%d')} - Showing actual HSRI values")
        # Use actual historical data
        data_to_map = data_for_date.copy()
        data_to_map['hsri'] = data_to_map.apply(
            lambda row: compute_hsri(
                row.get('temp', 70),
                row.get('humidity', 50),
                row.get('windspeed', 5),
                row.get('solarradiation', 500),
                row.get('uvindex', 5),
                row.get('cloudcover', 50)
            ), axis=1
        )
        is_forecast = False
        forecast_data_all = None
    else:
        st.info(f"üìä No historical data for {target_date.strftime('%Y-%m-%d')} - Showing forecast")
        # Generate forecast for all sites
        forecast_data_all = {}
        for aqs_id in weather_df['aqs_id_full'].unique():
            site_data = weather_df[weather_df['aqs_id_full'] == aqs_id].sort_values('datetime').tail(50).copy()
            if len(site_data) > 10:  # Need at least 10 records to forecast
                # Compute HSRI for historical data
                site_data['hsri'] = site_data.apply(
                    lambda row: compute_hsri(
                        row.get('temp', 70),
                        row.get('humidity', 50),
                        row.get('windspeed', 5),
                        row.get('solarradiation', 500),
                        row.get('uvindex', 5),
                        row.get('cloudcover', 50)
                    ), axis=1
                )
                forecast = forecast_hsri(site_data, days_ahead=3)
                if forecast:
                    forecast_data_all[aqs_id] = forecast
        is_forecast = True
        data_to_map = None
    
    if is_forecast and (forecast_data_all is None or not forecast_data_all):
        st.warning("‚ö†Ô∏è Insufficient data for generating forecasts. Make sure weather.csv has data with required columns.")
    elif not is_forecast and data_to_map is not None and not data_to_map.empty:
        # Create map with historical HSRI data
        hist_sites = sites_df[sites_df['aqs_id_full'].isin(data_to_map['aqs_id_full'].unique())]
        
        if not hist_sites.empty:
            center_lat = hist_sites['latitude'].mean()
            center_lon = hist_sites['longitude'].mean()
        else:
            center_lat = 40.7128
            center_lon = -74.0060
        
        if pd.isna(center_lat) or pd.isna(center_lon):
            center_lat = 40.7128
            center_lon = -74.0060
        
        m_forecast = folium.Map(
            location=[center_lat, center_lon],
            zoom_start=11,
            tiles='OpenStreetMap'
        )
        
        def get_marker_color(hsri_val):
            if hsri_val >= 85:
                return '#d62728'  # Critical - dark red
            elif hsri_val >= 75:
                return '#ff7f0e'  # High - orange
            elif hsri_val >= 65:
                return '#ffbb78'  # Moderate - light orange
            elif hsri_val >= 50:
                return '#2ca02c'  # Low - green
            elif hsri_val >= 30:
                return '#1f77b4'  # Cool - blue
            else:
                return '#6a0dad'  # Freezing - dark purple
        
        # Add historical markers
        for aqs_id in data_to_map['aqs_id_full'].unique():
            site_info = hist_sites[hist_sites['aqs_id_full'] == aqs_id]
            if not site_info.empty:
                site_row = site_info.iloc[0]
                site_data = data_to_map[data_to_map['aqs_id_full'] == aqs_id]
                
                # Get the HSRI value (should be one per site per day, but take mean if multiple)
                hsri_val = site_data['hsri'].mean()
                risk_emoji, risk_text = get_risk_category(hsri_val)
                
                popup_text = f"""
                <div style="font-family: Arial; width: 300px;">
                    <b style="font-size: 14px;">{site_row['site_name']}</b><br/>
                    <hr style="margin: 5px 0;">
                    <b>County:</b> {site_row['county']}<br/>
                    <b>üìÖ Date:</b> {target_date.strftime('%Y-%m-%d')}<br/>
                    <hr style="margin: 5px 0;">
                    <b style="font-size: 13px;">Actual HSRI: {hsri_val:.1f}</b><br/>
                    <b>{risk_emoji} {risk_text}</b>
                </div>
                """
                
                folium.CircleMarker(
                    location=[site_row['latitude'], site_row['longitude']],
                    radius=16,
                    popup=folium.Popup(popup_text, max_width="300px"),
                    tooltip=f"{site_row['site_name']}: HSRI {hsri_val:.1f}",
                    color=get_marker_color(hsri_val),
                    fill=True,
                    fillColor=get_marker_color(hsri_val),
                    fillOpacity=0.7,
                    weight=2
                ).add_to(m_forecast)
                
                # Add text label
                text_color = '#333333' if 50 <= hsri_val < 75 else 'white'
                text_shadow = '1px 1px 2px rgba(255,255,255,0.8)' if 50 <= hsri_val < 75 else '1px 1px 2px rgba(0,0,0,0.8)'
                
                folium.Marker(
                    location=[site_row['latitude'], site_row['longitude']],
                    icon=folium.DivIcon(html=f"""
                    <div style="
                        font-size: 13px;
                        font-weight: bold;
                        color: {text_color};
                        text-align: center;
                        text-shadow: {text_shadow};
                        width: 32px;
                        height: 32px;
                        display: flex;
                        align-items: center;
                        justify-content: center;
                        margin-left: -16px;
                        margin-top: -16px;
                    ">{hsri_val:.0f}</div>
                """)
                ).add_to(m_forecast)
        
        st_folium(m_forecast, width=1400, height=700)
        
        # Summary statistics
        st.divider()
        st.subheader("üìä Historical HSRI Statistics")
        
        col1, col2, col3, col4, col5 = st.columns(5)
        all_hsri_values = data_to_map['hsri'].dropna()
        
        with col1:
            avg_hsri = all_hsri_values.mean()
            st.metric("üìä Avg HSRI", f"{avg_hsri:.1f}¬∞F")
        
        with col2:
            max_hsri = all_hsri_values.max()
            risk_emoji, risk_text = get_risk_category(max_hsri)
            st.metric("üî• Peak HSRI", f"{max_hsri:.1f}¬∞F", delta=risk_text)
        
        with col3:
            min_hsri = all_hsri_values.min()
            st.metric("‚ùÑÔ∏è Min HSRI", f"{min_hsri:.1f}¬∞F")
        
        with col4:
            high_risk_count = sum(1 for val in all_hsri_values if val >= hsri_threshold)
            st.metric("‚ö†Ô∏è High-Risk Sites", high_risk_count)
        
        with col5:
            st.metric("üìÖ Date", target_date.strftime('%b %d, %Y'))
    
    elif is_forecast and forecast_data_all:
        # Create forecast map with forecasted HSRI
        sites_with_forecast = sites_df[sites_df['aqs_id_full'].isin(forecast_data_all.keys())]
        
        if not sites_with_forecast.empty:
            center_lat = sites_with_forecast['latitude'].mean()
            center_lon = sites_with_forecast['longitude'].mean()
        else:
            center_lat = 40.7128
            center_lon = -74.0060
        
        if pd.isna(center_lat) or pd.isna(center_lon):
            center_lat = 40.7128
            center_lon = -74.0060
        
        m_forecast = folium.Map(
            location=[center_lat, center_lon],
            zoom_start=11,
            tiles='OpenStreetMap'
        )
        
        def get_marker_color(hsri_val):
            if hsri_val >= 85:
                return '#d62728'  # Critical - dark red
            elif hsri_val >= 75:
                return '#ff7f0e'  # High - orange
            elif hsri_val >= 65:
                return '#ffbb78'  # Moderate - light orange
            elif hsri_val >= 50:
                return '#2ca02c'  # Low - green
            elif hsri_val >= 30:
                return '#1f77b4'  # Cool - blue
            else:
                return '#6a0dad'  # Freezing - dark purple
        
        # Add markers for each site with forecasted HSRI
        for _, row in sites_with_forecast.iterrows():
            aqs_id = row.get('aqs_id_full')
            site_name = row.get('site_name', 'Unknown')
            county = row.get('county', 'Unknown')
            
            if aqs_id in forecast_data_all:
                forecast_values = forecast_data_all[aqs_id]
                forecasted_hsri = forecast_values[forecast_day - 1]
                risk_emoji, risk_text = get_risk_category(forecasted_hsri)
                
                popup_text = f"""
                <div style="font-family: Arial; width: 300px;">
                    <b style="font-size: 14px;">{site_name}</b><br/>
                    <hr style="margin: 5px 0;">
                    <b>County:</b> {county}<br/>
                    <b>üìÖ Date:</b> {(pd.Timestamp(closest_time) + timedelta(days=forecast_day)).strftime('%Y-%m-%d')}<br/>
                    <hr style="margin: 5px 0;">
                    <b style="font-size: 13px;">Forecast HSRI: {forecasted_hsri:.1f}</b><br/>
                    <b>{risk_emoji} {risk_text}</b>
                </div>
                """
                
                folium.CircleMarker(
                    location=[row['latitude'], row['longitude']],
                    radius=16,
                    popup=folium.Popup(popup_text, max_width="300px"),
                    tooltip=f"{site_name}: Forecast HSRI {forecasted_hsri:.1f}",
                    color=get_marker_color(forecasted_hsri),
                    fill=True,
                    fillColor=get_marker_color(forecasted_hsri),
                    fillOpacity=0.7,
                    weight=2
                ).add_to(m_forecast)
                
                # Add text label with forecasted HSRI value
                text_color = '#333333' if 50 <= forecasted_hsri < 75 else 'white'
                text_shadow = '1px 1px 2px rgba(255,255,255,0.8)' if 50 <= forecasted_hsri < 75 else '1px 1px 2px rgba(0,0,0,0.8)'
                
                folium.Marker(
                    location=[row['latitude'], row['longitude']],
                    icon=folium.DivIcon(html=f"""
                    <div style="
                        font-size: 13px;
                        font-weight: bold;
                        color: {text_color};
                        text-align: center;
                        text-shadow: {text_shadow};
                        width: 32px;
                        height: 32px;
                        display: flex;
                        align-items: center;
                        justify-content: center;
                        margin-left: -16px;
                        margin-top: -16px;
                    ">{forecasted_hsri:.0f}</div>
                """)
                ).add_to(m_forecast)
        
        st_folium(m_forecast, width=1400, height=700)
        
        # Summary statistics for forecast
        st.divider()
        st.subheader("üìä Forecast Summary Statistics")
        
        all_forecast_values = [forecast_data_all[aqs_id][forecast_day - 1] for aqs_id in forecast_data_all]
        
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            avg_hsri = np.mean(all_forecast_values)
            st.metric("üìä Avg Forecast HSRI", f"{avg_hsri:.1f}¬∞F")
        
        with col2:
            max_hsri = np.max(all_forecast_values)
            risk_emoji, risk_text = get_risk_category(max_hsri)
            st.metric("üî• Peak Forecast HSRI", f"{max_hsri:.1f}¬∞F", delta=risk_text)
        
        with col3:
            min_hsri = np.min(all_forecast_values)
            st.metric("‚ùÑÔ∏è Min Forecast HSRI", f"{min_hsri:.1f}¬∞F")
        
        with col4:
            high_risk_count = sum(1 for val in all_forecast_values if val >= hsri_threshold)
            st.metric("‚ö†Ô∏è High-Risk Sites", high_risk_count)
        
        with col5:
            forecast_date = (pd.Timestamp(closest_time) + timedelta(days=forecast_day)).strftime('%b %d, %Y')
            st.metric("üìÖ Forecast Date", forecast_date)

# ====================================================================
# TAB 4: FINANCIAL IMPACT
# ====================================================================
with tab_financial:
    st.header("üí∞ Financial Impact Analysis")
    st.markdown("**ROI and cost-benefit analysis of the predictive HSRI forecasting system**")
    
    # Financial parameters
    baseline_annual_cost = 227.5e6  # Current reactive system (NYC cooling centers)
    proposed_annual_operating = 3210  # Our system annual operational cost ($3.21K)
    implementation_cost = 215000  # One-time implementation
    cooling_center_savings = 80e6  # Annual savings from targeted operations
    healthcare_savings = 10.2e6  # Annual ED visit prevention savings
    
    # Model performance
    model_r_squared = 0.962
    model_rmse = 3.0
    
    # Columns for cost comparison
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            "üèõÔ∏è Current System (Annual)",
            f"${baseline_annual_cost/1e6:.1f}M",
            help="NYC reactive cooling center model"
        )
    
    with col2:
        st.metric(
            "ü§ñ Proposed System (Annual)",
            f"${proposed_annual_operating/1e3:.2f}K",
            help="Predictive ML system operational costs (weather API, cloud compute, storage, alerts)"
        )
    
    with col3:
        st.metric(
            "üíæ First-Year Implementation",
            f"${implementation_cost/1e3:.0f}K",
            help="Development, integration, testing, training"
        )
    
    st.divider()
    
    # ROI Analysis
    st.subheader("üìà Return on Investment (ROI)")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        annual_savings = baseline_annual_cost - proposed_annual_operating
        roi_pct = ((annual_savings - implementation_cost) / implementation_cost) * 100
        st.metric(
            "Annual Savings (Operational)",
            f"${annual_savings/1e6:.2f}M",
            delta=f"{roi_pct/100:.0f}x ROI"
        )
    
    with col2:
        payback_days = (implementation_cost / annual_savings) * 365
        st.metric(
            "Payback Period",
            f"{payback_days:.1f} days",
            delta="First-year break-even"
        )
    
    with col3:
        five_year_cumulative = (annual_savings * 5) - (implementation_cost + proposed_annual_operating * 5)
        st.metric(
            "5-Year Cumulative Savings",
            f"${five_year_cumulative/1e6:.1f}M",
            delta="Net benefit after costs"
        )
    
    st.divider()
    
    # Cost Breakdown
    st.subheader("üí∏ Annual Operating Cost Breakdown")
    
    cost_components = {
        "Weather Data API": 420,
        "Cloud Infrastructure (AWS EC2)": 2100,
        "Data Storage (S3 + RDS)": 90,
        "Alert System (SNS)": 600,
    }
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # Create pie chart
        fig = go.Figure(data=[go.Pie(
            labels=list(cost_components.keys()),
            values=list(cost_components.values()),
            hovertemplate="<b>%{label}</b><br>$%{value:,.0f}<br>%{percent}<extra></extra>",
            marker=dict(colors=["#636EFA", "#EF553B", "#00CC96", "#AB63FA"])
        )])
        fig.update_layout(
            title="Annual Operating Costs ($3,210 total)",
            height=400,
            showlegend=True
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.markdown("### Cost Components\n")
        total = sum(cost_components.values())
        for component, cost in cost_components.items():
            pct = (cost / total) * 100
            st.markdown(f"**{component}**  \n${cost:,} ({pct:.1f}%)")
    
    st.divider()
    
    # Where does $80M in savings come from?
    st.subheader("üìä Where Do the Savings Come From?")
    
    st.markdown("""
    **The Key Insight:** NYC's current system opens all 600+ cooling centers **simultaneously** whenever a heat emergency is declared, 
    regardless of whether each neighborhood actually needs them. This blanket approach wastes resources.
    
    Our predictive model uses **neighborhood-level HSRI forecasts** to open cooling centers **only where they're needed**:
    """)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        #### Current Model (All or Nothing)
        - **Open:** 100% of facilities on all ~30 heat emergency days/year
        - **Daily cost when active:** $6.67M
        - **Annual cost:** $6.67M √ó 30 days = **$200M/year**
        - **Problem:** Many centers sit empty while all must be staffed
        """)
    
    with col2:
        st.markdown("""
        #### Our Predictive Model (Targeted)
        - **Open:** ~60% of facilities (based on HSRI forecast)
        - **Daily cost:** $6.67M √ó 60% = $4.00M
        - **Annual cost:** $4.00M √ó 30 days = **$120M/year**
        - **Benefit:** Centers open only where risk is highest; better service in those areas
        """)
    
    st.markdown("""
    ### Savings Breakdown
    | Category | Amount |
    |----------|--------|
    | Cooling Center Efficiency | **$80M/year** |
    | Prevented ED Visits | **$10.2M/year** |
    | Staff Overtime Reduction | **$5-8M/year** |
    | Energy Cost Savings | **$2-3M/year** |
    | **Total Annual Benefit** | **$97-105M/year** |
    | **System Operating Cost** | **$3.21K/year** |
    | **Net Annual Savings** | **$97-105M/year** |
    """)
    
    # Visualization: Cost comparison over time
    st.markdown("### Cost Comparison: Current vs. Proposed System")
    
    # Generate example data showing daily costs across a summer season
    import pandas as pd
    
    days_in_season = 120  # Summer season
    np.random.seed(42)
    
    # Simulate HSRI values across the season (low baseline, occasional spikes)
    base_hsri = np.random.normal(65, 10, days_in_season)
    # Add heat wave events
    heat_waves = [(30, 40), (75, 85), (110, 120)]
    for start, end in heat_waves:
        base_hsri[start:end] += np.random.uniform(15, 30, end-start)
    
    # Fraction of neighborhoods needing cooling centers (correlates with HSRI)
    frac_needed = np.clip((base_hsri - 50) / 50, 0, 1)
    
    # Daily costs
    daily_cost_current = np.where(frac_needed > 0, 6.67, 0)  # Open all or nothing
    daily_cost_proposed = frac_needed * 6.67  # Proportional to need
    
    # Create dataframe
    sim_data = pd.DataFrame({
        'Day': range(1, days_in_season + 1),
        'HSRI (Avg)': base_hsri,
        'Current Model ($M)': daily_cost_current,
        'Proposed Model ($M)': daily_cost_proposed,
    })
    
    # Cumulative costs
    sim_data['Current Model Cumulative ($M)'] = sim_data['Current Model ($M)'].cumsum()
    sim_data['Proposed Model Cumulative ($M)'] = sim_data['Proposed Model ($M)'].cumsum()
    
    # Plot cumulative costs over season
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=sim_data['Day'],
        y=sim_data['Current Model Cumulative ($M)'],
        name='Current Model (All or Nothing)',
        line=dict(color='#d62728', width=3),
        hovertemplate='<b>Day %{x}</b><br>Cumulative Cost: $%{y:.1f}M<extra></extra>'
    ))
    
    fig.add_trace(go.Scatter(
        x=sim_data['Day'],
        y=sim_data['Proposed Model Cumulative ($M)'],
        name='Proposed Model (Targeted)',
        line=dict(color='#2ca02c', width=3),
        hovertemplate='<b>Day %{x}</b><br>Cumulative Cost: $%{y:.1f}M<extra></extra>'
    ))
    
    # Add shaded area showing savings
    fig.add_trace(go.Scatter(
        x=sim_data['Day'].tolist() + sim_data['Day'].tolist()[::-1],
        y=sim_data['Current Model Cumulative ($M)'].tolist() + sim_data['Proposed Model Cumulative ($M)'].tolist()[::-1],
        fill='toself',
        fillcolor='rgba(44, 160, 44, 0.2)',
        line=dict(color='rgba(255,255,255,0)'),
        hoverinfo='skip',
        name='Savings Region'
    ))
    
    final_current = sim_data['Current Model Cumulative ($M)'].iloc[-1]
    final_proposed = sim_data['Proposed Model Cumulative ($M)'].iloc[-1]
    season_savings = final_current - final_proposed
    
    fig.update_layout(
        title=f'120-Day Summer Season: Cumulative Cost Comparison<br><sub>Seasonal Savings: ${season_savings:.1f}M (40% reduction)</sub>',
        xaxis_title='Days in Season',
        yaxis_title='Cumulative Cost ($M)',
        hovermode='x unified',
        height=400,
        legend=dict(x=0.02, y=0.98),
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Daily costs chart
    col1, col2 = st.columns([2, 1])
    
    with col1:
        fig2 = go.Figure()
        
        fig2.add_trace(go.Scatter(
            x=sim_data['Day'],
            y=sim_data['Current Model ($M)'],
            name='Current (All or Nothing)',
            fill='tozeroy',
            fillcolor='rgba(214, 39, 40, 0.3)',
            line=dict(color='#d62728', width=2),
            hovertemplate='<b>Day %{x}</b><br>Daily Cost: $%{y:.2f}M<extra></extra>'
        ))
        
        fig2.add_trace(go.Scatter(
            x=sim_data['Day'],
            y=sim_data['Proposed Model ($M)'],
            name='Proposed (Targeted)',
            fill='tozeroy',
            fillcolor='rgba(44, 160, 44, 0.3)',
            line=dict(color='#2ca02c', width=2),
            hovertemplate='<b>Day %{x}</b><br>Daily Cost: $%{y:.2f}M<extra></extra>'
        ))
        
        fig2.update_layout(
            title='Daily Operating Costs Across Season',
            xaxis_title='Days in Season',
            yaxis_title='Daily Cost ($M)',
            hovermode='x unified',
            height=350,
        )
        
        st.plotly_chart(fig2, use_container_width=True)
    
    with col1:
        # Summary statistics
        total_current = sim_data['Current Model ($M)'].sum()
        total_proposed = sim_data['Proposed Model ($M)'].sum()
        avg_savings_per_day = (total_current - total_proposed) / days_in_season
        
        st.markdown(f"""
        #### Season Summary (120 days)
        
        | Metric | Current Model | Proposed Model | Savings |
        |--------|---------------|----------------|---------|
        | **Total Cost** | ${total_current:.1f}M | ${total_proposed:.1f}M | **${total_current - total_proposed:.1f}M** |
        | **Avg Daily Cost** | ${total_current/days_in_season:.2f}M | ${total_proposed/days_in_season:.2f}M | ${avg_savings_per_day:.2f}M/day |
        | **Days Active** | {(sim_data['Current Model ($M)'] > 0).sum()} | {(sim_data['Proposed Model ($M)'] > 0).sum()} | - |
        
        **Extrapolated to Full Year (365 days):**
        - Current: ${(total_current/days_in_season)*365:.1f}M
        - Proposed: ${(total_proposed/days_in_season)*365:.1f}M
        - **Annual Savings: ${((total_current-total_proposed)/days_in_season)*365:.1f}M**
        """)
    
    st.divider()
    st.subheader("‚ù§Ô∏è Health & Societal Benefits")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "ED Visits Prevented",
            "1,360/year",
            delta="40% reduction",
            help="Emergency Department visits from heat stress"
        )
    
    with col2:
        st.metric(
            "Healthcare Savings",
            "$10.2M/year",
            delta="$7,500 per visit",
            help="Direct medical cost avoidance"
        )
    
    with col3:
        st.metric(
            "Lives Saved",
            "~100/year",
            delta="20% mortality reduction",
            help="Conservative estimate from early warnings"
        )
    
    with col4:
        st.metric(
            "Social Value",
            "$1.05B/year",
            delta="$10.5M per life (EPA VSL)",
            help="Statistical value of life saved"
        )
    
    st.divider()
    
    # Cooling Center Efficiency
    st.subheader("üè¢ Cooling Center Optimization")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### Current Reactive Model
        - **Activation:** All 600+ centers open simultaneously
        - **Trigger:** Fixed temperature thresholds (citywide)
        - **Cost per day:** $6.67 million
        - **Efficiency:** 100% of facilities, ~30% actual utilization
        - **Result:** Unnecessary overhead, inefficient resource allocation
        """)
    
    with col2:
        st.markdown("""
        ### Proposed Predictive Model
        - **Activation:** Neighborhood-specific based on HSRI forecast
        - **Trigger:** 3-hour advance warning via machine learning
        - **Cost per day:** ~$4M (40% reduction)
        - **Efficiency:** 60-70% of facilities actually needed
        - **Result:** Targeted response, better service quality
        """)
    
    st.divider()
    
    # Model Performance
    st.subheader("üéØ Predictive Model Performance")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            "Model R¬≤ Score",
            f"{model_r_squared:.1%}",
            help="Explains 96.2% of heat stress variance"
        )
    
    with col2:
        st.metric(
            "Prediction RMSE",
            f"¬±{model_rmse:.1f}¬∞F",
            help="Root Mean Squared Error vs. observed"
        )
    
    with col3:
        st.metric(
            "MAE",
            "¬±$2.19M",
            help="Mean Absolute Error in cost predictions"
        )
    
    st.markdown("""
    **Model Details:**
    - Algorithm: Linear Regression (interpretability prioritized for operational deployment)
    - Features: Temperature, humidity, wind speed, solar radiation, UV index, cloud cover
    - Training Data: 2-year historical weather observations (49 NYC neighborhoods)
    - Forecast Horizon: 1-3 days ahead with neighborhood-level granularity
    """)
    
    st.divider()
    
    # Implementation Costs
    st.subheader("üõ†Ô∏è One-Time Implementation Costs")
    
    implementation_breakdown = {
        "System Development": 75000,
        "NYC Integration": 75000,
        "Testing & Validation": 37500,
        "Training & Documentation": 15000,
    }
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.markdown("### Breakdown\n")
        total_impl = sum(implementation_breakdown.values())
        for item, cost in implementation_breakdown.items():
            pct = (cost / total_impl) * 100
            st.markdown(f"{item}  \n**${cost/1e3:.0f}K** ({pct:.0f}%)")
        st.markdown(f"\n**Total:** ${total_impl/1e3:.0f}K")
    
    with col2:
        fig = go.Figure(data=[go.Bar(
            x=list(implementation_breakdown.keys()),
            y=list(implementation_breakdown.values()),
            marker=dict(color=["#1f77b4", "#ff7f0e", "#2ca02c", "#d62728"]),
            text=[f"${v/1e3:.0f}K" for v in implementation_breakdown.values()],
            textposition="outside",
            hovertemplate="<b>%{x}</b><br>$%{y:,.0f}<extra></extra>"
        )])
        fig.update_layout(
            title="Implementation Cost by Category",
            xaxis_title="",
            yaxis_title="Cost ($)",
            height=350,
            showlegend=False,
            yaxis_tickformat="$,.0f"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    st.divider()
    
    # Summary metrics
    st.subheader("üìä Key Metrics Summary")
    
    summary_data = {
        "Metric": [
            "First-Year ROI",
            "Break-Even",
            "Annual Cooling Center Savings",
            "Annual Healthcare Savings",
            "Annual System Cost",
            "5-Year Net Benefit",
            "Model Accuracy (R¬≤)",
            "Neighborhoods Served",
            "Alert Lead Time"
        ],
        "Value": [
            f"{((annual_savings - implementation_cost) / implementation_cost):.0%}",
            f"{payback_days:.1f} days",
            f"${cooling_center_savings/1e6:.1f}M",
            f"${healthcare_savings/1e6:.1f}M",
            f"${proposed_annual_operating/1e3:.2f}K",
            f"${five_year_cumulative/1e6:.0f}M",
            f"{model_r_squared:.1%}",
            "49",
            "3 hours"
        ]
    }
    
    summary_df = pd.DataFrame(summary_data)
    st.dataframe(summary_df, use_container_width=True, hide_index=True)
    
    st.divider()
    
    st.markdown("""
    ### Key Insights
    
    1. **Exceptional ROI**: The system pays for itself in 2 days and delivers 41,000% first-year ROI
    
    2. **Operational Efficiency**: By using neighborhood-level predictions, we reduce unnecessary cooling center activations by 40%
    
    3. **Health Impact**: Early warnings enable 20% reduction in heat-related mortality, saving lives worth $1.05B annually
    
    4. **Scalability**: Annual operating costs of just $3.2K make this highly scalable to other cities and regions
    
    5. **Decision-Maker Readiness**: 3-hour forecast lead time provides sufficient time for targeted public health interventions
    
    ### Implementation Timeline
    - **Weeks 1-4**: System development and NYC integration
    - **Weeks 5-6**: Testing, validation, and staff training
    - **Week 7**: Deployment and go-live
    - **Ongoing**: Daily forecasts and continuous model refinement
    
    ---
    
    **Contact:** For implementation inquiries or technical details, contact the project team.
    """)

# ====================================================================
# TAB 5: ABOUT
# ====================================================================
with tab_about:
    st.markdown("""
    # About This Dashboard
    
    #Team
    Members: Fabien M. De Silva Jr. fmd48@cornell.edu | Jose Ruben Salinas Aguilar js3873@cornell.edu | Anggasta Anindityo aa2938@cornell.edu
    Institution: Cornell University, SYSEN
    Course: SYSEN 5300 - Systems Engineering and Six Sigma
    Year: Fall 2025
    
    ## Project Overview
    This Heat Stress Risk Index (HSRI) Weather Dashboard is a real-time monitoring and forecasting system 
    designed to reduce heat-related health impacts across the NYC metropolitan region. Developed as part of 
    Cornell University's SYSEN 5300 course, this project demonstrates predictive analytics for public health resilience.
    
    ### Project Goals
    - **Reduce hospital admissions** by 20% through early warning and targeted interventions
    - **Lower healthcare costs** by 40% via proactive cooling center placement and resource allocation
    - **Improve equity** by providing neighborhood-level forecasts for vulnerable populations
    - **Enable data-driven decision-making** for city planners, public health officials, and emergency managers
    
    ---
    
    ## How It Works
    
    ### Heat Stress Risk Index (HSRI)
    The HSRI combines multiple meteorological variables into a single indicator of heat stress risk:
    
    **Formula:**
    ```
    HSRI = HI + 0.3¬∑UV + 8¬∑SR_eff ‚àí 4¬∑WS ‚àí 0.05¬∑CC
    ```
    
    Where:
    - **HI**: NWS Heat Index (temperature + humidity effect)
    - **UV**: UV Index (radiant heat load, 0-10+)
    - **SR_eff**: Effective solar radiation (normalized, ~0-1)
    - **WS**: Wind speed (mph, cooling effect)
    - **CC**: Cloud cover (%, shading effect)
    
    ### Risk Categories
    - üî¥ **Critical** (‚â•85): Extreme danger - activate all emergency protocols
    - üü† **High** (‚â•75): Significant risk - increase cooling center capacity
    - üü° **Moderate** (‚â•65): Moderate risk - monitor vulnerable populations
    - üü¢ **Low** (‚â•50): Mild conditions - routine operations
    - üîµ **Cool** (30-49): Cool conditions - light layers recommended
    - üü£ **Freezing** (<30): Freezing conditions - winter coat required    
    ---
    
    ## Data & Model
    
    ### Data Source
    - **Weather Data**: Hourly observations from 56 AQS (Air Quality System) monitoring stations
    - **Geographic Coverage**: NYC metro region including 5 NYC boroughs, Westchester County, surrounding NJ areas, and CT
    - **Time Period**: 2018-01-01 to 2025-06-01 (continuous hourly records)
    - **Variables**: Temperature, humidity, wind speed, solar radiation, UV index, cloud cover
    
    ### Forecasting Model
    - **Algorithm**: Linear Regression
    - **Model Accuracy**: R¬≤ = 0.965, RMSE = 3.0¬∞F, MAE = 2.19¬∞F
    - **Horizon**: 1-3 day advance forecasts
    - **Rationale**: Prioritizes interpretability and operational feasibility over black-box approaches
    
    ### Data Quality
    - ‚úì Core meteorological parameters required (temp, humidity, windspeed)
    - ‚úì Hourly temporal resolution for real-time monitoring
    - ‚úì Multi-station coverage for geographic accuracy
    - ‚úì Solar, UV, cloud data optional (shows "N/A" when unavailable)
    - ‚úì Historical data spanning 2018-2025
    
    ---
    
    ## Key Features
    
    ### üìä Dashboard Tab
    - Real-time HSRI metrics (average, peak, distribution)
    - Borough/area filtering for localized analysis
    - 3-day HSRI forecast with uncertainty
    - Operational insights (cooling center readiness, healthcare alert levels)
    - Protective clothing recommendations by risk level

    ### üå¶Ô∏è Weather Details Tab
    - Expandable detailed weather for each location
    - All 6 meteorological variables with units
    - HSRI output and risk categorization
    - High-risk location data table with filtering
    
    ### ‚ÑπÔ∏è About Tab
    - Project background and goals
    - Technical documentation
    - Model performance metrics
    - How to interpret results
    
    ---
    
    ## Controls
    
    ### Dashboard Controls (Sidebar)
    - **Date Selector**: Choose observation date
    - **Hour Selector**: Select specific hour (UTC)
    - **HSRI Threshold**: Filter for high-risk locations
    - **Borough/Area**: View specific geographic regions
    - **3-Day Forecast**: Toggle predictive component
    
    ### Data Available
    - **Temporal Coverage**: 2018 to present (with historical data)
    - **Geographic Regions**: All NYC metro areas with active monitoring
    - **Borough Options**: Only shows areas with data at selected time
    
    ---
    
    ## Interpretation Guide
    
    ### For Public Health Officials
    - Monitor **Peak HSRI** to trigger emergency response protocols
    - Use **High-Risk Sites** count to allocate cooling center resources
    - Review **Most Affected County** for targeted interventions
    - Check **Healthcare Alert Level** to prepare ED capacity
    
    ### For City Planners
    - Use **3-Day Forecast** for advance planning
    - Identify chronically vulnerable areas through **HSRI Distribution**
    - Plan tree canopy and green space using **Solar Radiation** data
    - Consider wind corridors for natural cooling
    
    ### For Residents
    - Follow **Protective Clothing Guide** recommendations
    - Monitor **Peak HSRI** for personal outdoor activity planning
    - Check **Forecast** to prepare for future heat stress conditions
    - Know your nearest **Cooling Center** (via separate resource maps)
    
    ---
    
    ## Technical Details
    
    ### Data Processing
    1. Load hourly weather observations from CSV
    2. Filter for complete records (all 6 variables present)
    3. Map AQS IDs to geographic locations and counties
    4. Compute HSRI for each observation
    5. Categorize risk levels
    6. Generate forecasts using historical trends
    
    ### Map Visualization
    - Folium.js for interactive mapping
    - Color-coded circle markers for HSRI values
    - Popup information cards with all variables
    - Responsive zoom and pan controls
    
    ### Forecasting
    - Linear regression on 6-dimensional weather feature space
    - Trained on historical HSRI data
    - Future predictions based on trend extrapolation
    - Bounds: [-100, 100]¬∞F to allow natural winter and summer values
    
    ---
    
    ## Project Team
    - **Institution**: Cornell University, College of Engineering (Systems Engineering)
    - **Course**: SYSEN 5300 - Systems Engineering and Six Sigma for the Design and Operation of Reliable Systems
    - **Academic Year**: Fall 2025
    
    ### Application Stack
    - **Frontend**: Streamlit (Python web app framework)
    - **Data Processing**: Pandas, NumPy
    - **Visualization**: Plotly, Folium
    - **Machine Learning**: scikit-learn
    - **Deployment**: Cloud-ready for Streamlit Community Cloud
    
    ---
    
    ## Further Information
    
    ### Related Resources
    - [Weather - Tim fraser - GitHub](https://github.com/timothyfraser/sts/tree/3week/data/weather)       
    - [NWS Heat Index](https://www.weather.gov/media/epz/wxcalc/heatIndex.pdf)
    - [EPA UV Index Guide](https://www.epa.gov/sites/production/files/2015-09/documents/UV_Index_10.pdf)
    - [CDC Heat Stress Prevention](https://www.cdc.gov/niosh/topics/emres/cheathstress.html)
    - [NYC Office of Emergency Management](https://www1.nyc.gov/site/em/index.page)
    
    ### Data Licensing
    - Weather data sourced from EPA AQS (public domain)
    - County geographic data from U.S. Census (public domain)
    - **Code**: MIT License
    
    ### License & Attribution
    This project is licensed under the **MIT License**. If you use this code or dashboard, please credit:
    - **Fabien M. De Silva Jr.** (fmd48@cornell.edu)
    - **Jose Ruben Salinas Aguilar** (js3873@cornell.edu)
    - **Anggasta Anindityo** (aa2938@cornell.edu)
    - **Cornell University, SYSEN 5300**
    
    See [LICENSE](https://github.com/FMDX-7/ShortTermHeatStressForecasting/blob/main/LICENSE) for full terms.
    
    ### Access the Live Dashboard
    **Deployed and live at:** [https://hsri-forecast.streamlit.app/](https://hsri-forecast.streamlit.app/)
    
    ---
    
    *Last Updated: December 2025*
    """)

# ====================================================================
# FOOTER
# ====================================================================
st.divider()

col_footer1, col_footer2, col_footer3 = st.columns(3)

with col_footer1:
    st.caption("üìä **Data Source:** NYC Metro AQS Network")
    st.caption(f"üîÑ Last Update: {closest_time.strftime('%Y-%m-%d %H:%M UTC')}")

with col_footer2:
    st.caption("**Model Accuracy:** R¬≤ = 0.965, RMSE = 3.0¬∞F")
    st.caption("**Project:** SYSEN 5300 ‚Ä¢ Cornell University")

with col_footer3:
    st.caption("**Formula:** HSRI = HI + 0.3¬∑UV + 8¬∑SR - 4¬∑WS - 0.05¬∑CC")
    st.caption("**Coverage:** All Available Stations ‚Ä¢ Hourly Updates")
